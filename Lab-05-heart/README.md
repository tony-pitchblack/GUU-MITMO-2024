# Лабораторная работа 5
## Данные

*Набор данных:* В датасете *default.csv* моего варианта (17), все порядковые признаки уже оказались перекодированы и не было номинальных, поэтому я взял другой популярный классический датасет, в котором присутствовали неперекодированные категориальные признаки: [Heart Failure Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)

*Независимые переменные:*
Age, Sex, ChestPainType, RestingBP, Cholesterol, FastingBS, </br> RestingECG, MaxHR, ExerciseAngina, Oldpeak, ST_Slope,</br> HeartDisease</br>

*Зависимая переменная:* HeartDisease

*Метод ансамблирования:* Random Forest

## Порядок выполнения работы

1. Данные были разделены на двe выборки: обучающую 85% и тестовую 15%. Предварительный анализ обнаружил примерно равные доли классов.

2. Найденный с помощью кросс-валидации оптимизированный параметр $alpha$ для дерева с обрезкой ветвей оказался равен 0.002. В оптимальном поддереве количество узлов составило 49, поэтому графическое представление было построено для субоптимального поддерева меньшего размера с 11 узлами ![Image](https://github.com/tony-pitchblack/GUU-MITMO-2024/blob/68ca6a119f4a228419ca7f15db4d3a9a14f795ef/Lab-05-heart/image.png)

3. Поиск по сетке 7x7 для случайного леса дал оптимальное кол-во деревьев $B=40$ и количество предикторов на одном сплите $m=4$.

4. Наиболее точной оказалась модель дерева случайного леса, её $Accuracy$ на трейне составила 87%.

5. $Accuracy$ предсказания модели случайного леса на отложенных наблюдениях составила 86%, остальные метрики приведены в таблице

              precision    recall  f1-score

           0       0.81      0.86      0.83
           1       0.89      0.85      0.87 